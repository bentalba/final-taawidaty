# üö® CRITICAL DEPLOYMENT ISSUE - robots.txt

## Problem
The deployed `robots.txt` at https://taawidaty.ma/robots.txt contains **29 lines** with an invalid directive on line 29:
```
Content-signal: search=yes,ai-train=no
```

However, the git repository only has a **clean 3-line robots.txt**.

## Impact
- **SEO score stuck at 92** (should be 100)
- Invalid robots.txt causes crawling issues
- PageSpeed Insights audit fails

## Root Cause
Something in the **deployment pipeline or hosting platform** is adding 26 extra lines to robots.txt, including the invalid `Content-signal` directive.

## Solution

### 1. Verify Deployment Process
Check your hosting platform (Netlify, Vercel, cPanel, etc.) for:
- Any robots.txt injection or modification settings
- Build hooks that might modify robots.txt
- Server-side rewrites or redirects affecting robots.txt

### 2. Ensure Clean robots.txt Deployment
The `public/robots.txt` file in this repo is clean and valid:
```txt
# robots.txt for taawidaty.ma
# Last updated: 2025-11-03

User-agent: *
Allow: /

# Sitemap
Sitemap: https://taawidaty.ma/sitemap.xml

# DO NOT ADD ANY ADDITIONAL DIRECTIVES BELOW THIS LINE
```

### 3. AI Training Blocking
If you want to block AI training, use the separate `public/ai.txt` file instead of adding invalid directives to robots.txt.

### 4. Deployment Checklist
After deployment, verify:
```bash
curl https://taawidaty.ma/robots.txt
```

Should return ONLY the clean version (12 lines with comments, 3 actual directives).

### 5. Common Hosting Platform Issues

**Netlify:**
- Check `netlify.toml` for robots.txt modifications
- Check "Build & Deploy" > "Post processing" settings

**Vercel:**
- Check `vercel.json` for rewrites/redirects
- Check "Settings" > "General" for robots.txt options

**cPanel/Traditional Hosting:**
- Check `.htaccess` for mod_rewrite rules affecting robots.txt
- Check if robots.txt is being generated by CMS/framework

**Cloudflare:**
- Check "Transform Rules" for robots.txt modifications
- Check "Workers" that might intercept robots.txt

## Verification After Fix
1. Run PageSpeed Insights: https://pagespeed.web.dev/
2. Check "Crawling and Indexing" section
3. SEO score should jump from 92 to 100

## Status
- ‚úÖ Git repository has clean robots.txt
- ‚ùå Deployed version has invalid robots.txt
- üîÑ **ACTION REQUIRED:** Check deployment platform settings
